{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numbers\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2pagination = 'data/2-bed-manhattan-all.json'\n",
    "b2page = 'data/2-bed-manhattan-pages.json'\n",
    "\n",
    "b1pagination = 'data/1-bed-manhattan-all.json'\n",
    "b1page = 'data/1-bed-manhattan-pages.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2p_df = pd.read_json(b2pagination)\n",
    "b2u_df = pd.read_json(b2page)\n",
    "\n",
    "b1p_df = pd.read_json(b1pagination)\n",
    "b1u_df = pd.read_json(b1page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2o', b2p_df.shape)\n",
    "print('2u', b2u_df.shape)\n",
    "\n",
    "print('2o', b1p_df.shape)\n",
    "print('2u', b1u_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2p_df_no_dup = b2p_df.drop_duplicates(['url'], keep='first')\n",
    "b2u_df_no_dup = b2u_df.drop_duplicates(['url'], keep='first')\n",
    "\n",
    "b1p_df_no_dup = b1p_df.drop_duplicates(['url'], keep='first')\n",
    "b1u_df_no_dup = b1u_df.drop_duplicates(['url'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2o', b2p_df_no_dup.shape)\n",
    "print('2u', b2u_df_no_dup.shape)\n",
    "\n",
    "print('1o', b1p_df_no_dup.shape)\n",
    "print('1u', b1u_df_no_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_merge = pd.merge(b2p_df_no_dup, b2u_df_no_dup, on=['url'])\n",
    "b1_merge = pd.merge(b1p_df_no_dup, b1u_df_no_dup, on=['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_merge.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_merge.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_dropped = b2_merge.drop(['furnished', 'has_broker_fee', 'sqft'], axis=1)\n",
    "b1_dropped = b1_merge.drop(['furnished', 'has_broker_fee', 'sqft'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coln = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_continuous_coln = [\n",
    "    'baths',\n",
    "    'building_units',\n",
    "    'station_nearest_distance',\n",
    "    'station_total'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummies_coln = [\n",
    "    'building_type',\n",
    "    \n",
    "    \n",
    "       'amen_outdoor_space', 'amen_pets_allowed', 'amen_dishwasher',\n",
    "       'amen_doorman', 'amen_elevator', 'amen_gym', 'amen_laundry_in_building',\n",
    "       'amen_live_in_super', 'amen_parking', 'amen_laundry_in_unit' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummies_coln_neighbors = [\n",
    "    'building_type',\n",
    "    'neighborhood',\n",
    "    \n",
    "       'amen_outdoor_space', 'amen_pets_allowed', 'amen_dishwasher',\n",
    "       'amen_doorman', 'amen_elevator', 'amen_gym', 'amen_laundry_in_building',\n",
    "       'amen_live_in_super', 'amen_parking', 'amen_laundry_in_unit' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_keep_coln = [\n",
    "    'beds',\n",
    "    'baths',\n",
    "    \n",
    "    'neighborhood',\n",
    "    'building_units',\n",
    "    'building_type',\n",
    "    \n",
    "       'amen_outdoor_space', 'amen_pets_allowed', 'amen_dishwasher',\n",
    "       'amen_doorman', 'amen_elevator', 'amen_gym', 'amen_laundry_in_building',\n",
    "       'amen_live_in_super', 'amen_parking', 'amen_laundry_in_unit'     \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    print('\\nstart shape', df.shape)\n",
    "\n",
    "    # drop these columns that dn't hav emuch data\n",
    "    \n",
    "    # drop building types that couldn't be specified\n",
    "    dropping = df['building_type'] != -1\n",
    "    df = df[dropping]\n",
    "    print('\\n  dropping building_type -1: ', sum(~dropping))\n",
    "    \n",
    "    # drop rows that have negative continuous variable values (signaling an issue during scraping)\n",
    "    dropping = df['station_nearest_distance'] != -1\n",
    "    df = df[dropping]\n",
    "    print('\\n  dropping station_nearest_distance -1: ', sum(~dropping))\n",
    "    \n",
    "    dropping = df['station_nearest_total'] != -1\n",
    "    df = df[dropping]\n",
    "    print('\\n  dropping station_nearest_total -1: ', sum(~dropping))  \n",
    "    \n",
    "    dropping = df['building_stories'] != -1\n",
    "    df = df[dropping]\n",
    "    print('\\n  dropping building_stories -1: ', sum(~dropping))  \n",
    "\n",
    "    dropping = df['building_units'] != -1\n",
    "    df = df[dropping]\n",
    "    print('\\n  dropping building_units -1: ', sum(~dropping))  \n",
    "\n",
    "    \n",
    "    print('\\nend shape', df.shape)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_clean = clean(b2_dropped)\n",
    "b1_clean = clean(b1_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_neg_values(df):\n",
    "    print('\\n')\n",
    "    for col in df:\n",
    "        if isinstance(df[col].iloc[0], numbers.Real):\n",
    "            summation = sum(df[col] < 0)\n",
    "            print(col, summation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_values(df):\n",
    "    print('\\n')\n",
    "    for col in df:\n",
    "        print(col)\n",
    "        df[col].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df, col='price', threshold=1.5):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lowest_limit = df[col] >= q1 - (threshold * iqr)\n",
    "    highest_limit = df[col] <= q3 + (threshold * iqr)\n",
    "    return df[lowest_limit & highest_limit]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(b2_clean[y_coln])\n",
    "plt.savefig('boxplot-outliers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_valid_values(b2_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_valid_values(b1_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neg_values(b2_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neg_values(b1_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_out = remove_outlier(b2_clean, y_coln)\n",
    "df1_out = remove_outlier(b1_clean, y_coln)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df2_out[y_coln])\n",
    "plt.savefig('boxlplot-no-outlier.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_bed1 = 'data/clean_1-bed.pkl'\n",
    "pickle_bed2 = 'data/clean_2-bed.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_out.to_pickle(pickle_bed2)\n",
    "df1_out.to_pickle(pickle_bed1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb1 = pd.read_pickle(pickle_bed1)\n",
    "dfb2 = pd.read_pickle(pickle_bed2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfb2, dfb2[y_coln], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_cols = ['beds', 'baths']\n",
    "dfs_X_cols = ['beds', 'baths', 'sqft'] # furnished has None values\n",
    "dfb1_X_cols = ['baths']\n",
    "dfb2_X_cols = ['baths']\n",
    "dfb3_X_cols = ['baths']\n",
    "dummies = ['neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummies(df, y_col, x_cols, dummy_cols):\n",
    "            \n",
    "    dummy_df = pd.get_dummies(df, columns=dummy_cols, drop_first=True)\n",
    "    \n",
    "    agg_dummy_col_names = []\n",
    "    \n",
    "    for col_name in dummy_cols:\n",
    "        dummy_col_names = [col for col in dummy_df.columns if col_name + '_' in col]\n",
    "        agg_dummy_col_names += dummy_col_names\n",
    "    \n",
    "    cols = x_cols + agg_dummy_col_names\n",
    "    return (dummy_df, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns_val(df, y_col, x_cols, dummy_cols):\n",
    "    \"\"\"\n",
    "    Take dataframe and add dummy variables\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dummy_df, cols = add_dummies(df, y_col, x_cols, dummy_cols)\n",
    "    \n",
    "    return split_and_validate(dummy_df[cols], df[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_validate(X, y, test='lr'):\n",
    "    \"\"\"\n",
    "    Take dataframe with dummy variable and run regression model\n",
    "    \"\"\"\n",
    "\n",
    "    # perform train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # fit linear regression to training data\n",
    "    if test == 'lr':\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(X_train, y_train)\n",
    "\n",
    "        # score fit model on validation data\n",
    "        val_score = lr_model.score(X_val, y_val)        \n",
    "\n",
    "    # report results\n",
    "    print('\\nValidation R^2 score was:', val_score)\n",
    "    print('Feature coefficient results: \\n')\n",
    "    zipped = zip(X.columns, lr_model.coef_)\n",
    "    for feature, coef in zipped:\n",
    "        print(feature, ':', f'{coef:.2f}')\n",
    "    \n",
    "    return (X_train, X_val, y_train, y_val, lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trying including and excluding neighborhoods some amenities by changing values from x_dummies_coln.\n",
    "\"\"\"\n",
    "\n",
    "X_sample_train, X_sample_val, y_sample_train, y_sample_val, lr_model = split_columns_val(X_train, 'price', x_continuous_coln, x_dummies_coln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T16:53:57.810889Z",
     "start_time": "2019-10-11T16:53:57.803507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.6838318519764027\n",
      "testing score 0.7177806244606443\n"
     ]
    }
   ],
   "source": [
    "print('training score', lr_model.score(X_sample_train, y_sample_train))\n",
    "print('testing score', lr_model.score(X_sample_val, y_sample_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_with_dummies = add_dummies(X_test)\n",
    "y_hat = lr_model.predict(x_test_with_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_val, y_hat)\n",
    "plt.xlabel('Actual rental unit prices')\n",
    "plt.ylabel('Predicted rental unit prices')\n",
    "plt.title('Rental Prices for 2 bd Units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
